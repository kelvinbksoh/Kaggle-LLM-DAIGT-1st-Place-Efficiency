## Kaggle - LLM DAIGT (1st-Place-Efficiency-Solution)
- Solution summary: https://www.kaggle.com/competitions/llm-detect-ai-generated-text/discussion/471898 
- Notebook link: https://www.kaggle.com/code/xyzdivergence/llm-daigt-sub?scriptVersionId=153307051

###ARCHIVE CONTENTS
- `train_infer.py`: code for training and inferencing on the testing dataset
- `input` folder: training and testing dataset folder
  - `kf-dataset`: Generated kids frontier dataset
  - `llm-detect-ai-generated-text/train_essays.csv`: The original training dataset
  - `daigt-v2-train-dataset/train_v2_drcat_02.csv`: Kaggle published dataset

### Hardware: 
Kaggle Kernels only: Intel(R) Xeon(R) CPU @ 2.20GHz


### Software
- Python 3.10.12
- Library dependencies: see the `requirements.txt` for details.


### Environment setup
```
$ conda create --name daigt python=3.10.12
$ conda activate daigt
$ pip install -r requirements.txt
```

### Training + Infer
The script:`train_infer.py` performs the following preprocessing and training on both training dataset + testing dataset (Unseen from Kaggle).

1. Train a custom Byte-pair encoding tokenizer on the “public + private” test set to generate tokens from the test set. This will use the BPE tokenized to generate tokens for both the training and test set.
2. Train a TFIDFVectorizer on the tokenized test set to generate the test vocabulary.
3. Train another TFIDFVectorizer using the test set vocabulary generated by point 2 above. This train on all the tokenized train set.
4. Train three classifier model on top of the TFIDF vectors in point 1 above,
      -  MultinomialNB
      -  SGDClassifier
      -  LGBMClassifier
5. Perform ensembling using a VotingClassifier of the above mentioned three classifiers with the following weights
      -  MultinomialNB * 0.3
      -  SGDClassifier * 0.3
      -  LGBMClassifier * 0.4

Arguments:
- -\-test_essays: "This is the test_essays.csv from the "public + private" test set
```
$ python train_infer.py --test_essays ''input/llm-detect-ai-generated-text/test_essays.csv"
```
submission.csv will be generated in the same folder.

### License
All of our solution code is open-sourced under the MIT license as stated in the competition <a href="https://www.kaggle.com/competitions/llm-detect-ai-generated-text/rules">rules</a>.